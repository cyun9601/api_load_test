import asyncio
import time
import statistics
from typing import List, Dict, Optional, BinaryIO
from dataclasses import dataclass
from datetime import datetime
import json
import io
import random
import numpy as np
import wave
import yaml
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ì´ ì‚¬ìš©


@dataclass
class TestResult:
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    response_time: float
    success: bool
    error: Optional[str] = None


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    median_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float


class STTLoadTester:
    """STT ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤í„°"""
    
    def __init__(
        self,
        api_call_func,
        audio_generator_func,
        total_requests: int,
        warmup_requests: int,
        concurrent_requests: int = 1,
        request_delay: float = 0.0
    ):
        """
        Args:
            api_call_func: STT APIë¥¼ í˜¸ì¶œí•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ (audio_data: io.BytesIOë¥¼ ì¸ìë¡œ ë°›ìŒ)
            audio_generator_func: ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (io.BytesIOë¥¼ ë°˜í™˜)
            total_requests: ì´ ìš”ì²­ ìˆ˜ (N)
            warmup_requests: ë²„ë¦´ warm-up ìš”ì²­ ìˆ˜ (M)
            concurrent_requests: ë™ì‹œ ìš”ì²­ ìˆ˜
            request_delay: ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)
        """
        self.api_call_func = api_call_func
        self.audio_generator_func = audio_generator_func
        self.total_requests = total_requests
        self.warmup_requests = warmup_requests
        self.concurrent_requests = concurrent_requests
        self.request_delay = request_delay
        self.results: List[TestResult] = []  # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼
        self.warmup_results: List[TestResult] = []  # Cold start (warmup) ê²°ê³¼
    
    async def _make_request(self, request_id: int) -> TestResult:
        """ë‹¨ì¼ ìš”ì²­ ì‹¤í–‰ (ì˜¤ë””ì˜¤ ìƒì„± ì‹œê°„ ì œì™¸)"""
        # ì˜¤ë””ì˜¤ ìƒì„± (ì‹œê°„ ì¸¡ì • ì œì™¸)
        audio_data = self.audio_generator_func()
        
        # API í˜¸ì¶œë§Œ ì‹œê°„ ì¸¡ì •ì— í¬í•¨
        start_time = time.time()
        try:
            await self.api_call_func(audio_data)
            response_time = time.time() - start_time
            return TestResult(response_time=response_time, success=True)
        except Exception as e:
            response_time = time.time() - start_time
            return TestResult(
                response_time=response_time,
                success=False,
                error=str(e)
            )
    
    async def _run_requests(self, num_requests: int, is_warmup: bool = False) -> List[TestResult]:
        """ìš”ì²­ ë°°ì¹˜ ì‹¤í–‰"""
        results = []
        semaphore = asyncio.Semaphore(self.concurrent_requests)
        
        async def bounded_request(request_id: int):
            async with semaphore:
                if self.request_delay > 0:
                    await asyncio.sleep(self.request_delay)
                result = await self._make_request(request_id)
                if is_warmup:
                    # Warmup (cold start) ê²°ê³¼ ì €ì¥
                    self.warmup_results.append(result)
                else:
                    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
                    results.append(result)
                    self.results.append(result)
                return result
        
        tasks = [bounded_request(i) for i in range(num_requests)]
        await asyncio.gather(*tasks)
        
        return results
    
    async def run(self) -> PerformanceMetrics:
        """ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"ğŸš€ STT ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"   ì´ ìš”ì²­ ìˆ˜: {self.total_requests}")
        print(f"   Warm-up ìš”ì²­ ìˆ˜: {self.warmup_requests}")
        print(f"   ë™ì‹œ ìš”ì²­ ìˆ˜: {self.concurrent_requests}")
        print(f"   ì‹¤ì œ ì¸¡ì • ìš”ì²­ ìˆ˜: {self.total_requests - self.warmup_requests}")
        print(f"   ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆë¡œìš´ ëœë¤ ì˜¤ë””ì˜¤ ìƒì„±")
        print()
        
        # Warm-up ë‹¨ê³„
        if self.warmup_requests > 0:
            print(f"ğŸ”¥ Warm-up ë‹¨ê³„ ({self.warmup_requests}ê°œ ìš”ì²­)...")
            warmup_start = time.time()
            await self._run_requests(self.warmup_requests, is_warmup=True)
            warmup_time = time.time() - warmup_start
            print(f"   Warm-up ì™„ë£Œ (ì†Œìš” ì‹œê°„: {warmup_time:.2f}ì´ˆ)")
            print()
        
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„
        print(f"ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ë‹¨ê³„ ({self.total_requests - self.warmup_requests}ê°œ ìš”ì²­)...")
        test_start = time.time()
        await self._run_requests(self.total_requests - self.warmup_requests, is_warmup=False)
        test_time = time.time() - test_start
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        return self._calculate_metrics(test_time)
    
    def _calculate_metrics(self, total_time: float) -> PerformanceMetrics:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.results:
            raise ValueError("í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        response_times = [r.response_time for r in self.results]
        successful_results = [r for r in self.results if r.success]
        failed_results = [r for r in self.results if not r.success]
        
        successful_response_times = [r.response_time for r in successful_results]
        
        if not successful_response_times:
            raise ValueError("ì„±ê³µí•œ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        sorted_times = sorted(successful_response_times)
        n = len(sorted_times)
        
        return PerformanceMetrics(
            total_requests=len(self.results),
            successful_requests=len(successful_results),
            failed_requests=len(failed_results),
            avg_response_time=statistics.mean(successful_response_times),
            min_response_time=min(successful_response_times),
            max_response_time=max(successful_response_times),
            median_response_time=statistics.median(sorted_times),
            p95_response_time=sorted_times[int(n * 0.95)] if n > 0 else 0,
            p99_response_time=sorted_times[int(n * 0.99)] if n > 0 else 0,
            requests_per_second=len(self.results) / total_time if total_time > 0 else 0
        )
    
    def print_results(self, metrics: PerformanceMetrics):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        print(f"ì´ ìš”ì²­ ìˆ˜: {metrics.total_requests}")
        print(f"ì„±ê³µí•œ ìš”ì²­: {metrics.successful_requests} ({metrics.successful_requests/metrics.total_requests*100:.1f}%)")
        print(f"ì‹¤íŒ¨í•œ ìš”ì²­: {metrics.failed_requests} ({metrics.failed_requests/metrics.total_requests*100:.1f}%)")
        print()
        print("ì‘ë‹µ ì‹œê°„ í†µê³„:")
        print(f"  í‰ê· : {metrics.avg_response_time:.3f}ì´ˆ")
        print(f"  ì¤‘ì•™ê°’: {metrics.median_response_time:.3f}ì´ˆ")
        print(f"  ìµœì†Œ: {metrics.min_response_time:.3f}ì´ˆ")
        print(f"  ìµœëŒ€: {metrics.max_response_time:.3f}ì´ˆ")
        print(f"  P95: {metrics.p95_response_time:.3f}ì´ˆ")
        print(f"  P99: {metrics.p99_response_time:.3f}ì´ˆ")
        print()
        print(f"ì²˜ë¦¬ëŸ‰: {metrics.requests_per_second:.2f} ìš”ì²­/ì´ˆ")
        print("="*60)
        
        # ì‹¤íŒ¨í•œ ìš”ì²­ ìƒì„¸ ì •ë³´
        if metrics.failed_requests > 0:
            print("\nâŒ ì‹¤íŒ¨í•œ ìš”ì²­ ìƒì„¸:")
            for i, result in enumerate(self.results):
                if not result.success:
                    print(f"  ìš”ì²­ #{i+1}: {result.error}")
    
    def save_histogram(self, filename: Optional[str] = None):
        """ì‘ë‹µ ì‹œê°„ ë„ìˆ˜ë¶„í¬í‘œ(íˆìŠ¤í† ê·¸ë¨)ë¥¼ ì €ì¥ (Cold startì™€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ êµ¬ë¶„)"""
        # Cold start (warmup)ì™€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
        warmup_response_times = [r.response_time for r in self.warmup_results if r.success]
        performance_response_times = [r.response_time for r in self.results if r.success]
        
        if not warmup_response_times and not performance_response_times:
            print("âš ï¸ ì„±ê³µí•œ ìš”ì²­ì´ ì—†ì–´ íˆìŠ¤í† ê·¸ë¨ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"response_time_histogram_{timestamp}.png"
        
        # Font settings
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        
        # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
        fig, ax = plt.subplots(figsize=(12, 7))
        
        # ëª¨ë“  ì‘ë‹µ ì‹œê°„ì„ í•©ì³ì„œ bins ë²”ìœ„ ê²°ì •
        all_times = warmup_response_times + performance_response_times
        if all_times:
            min_time = min(all_times)
            max_time = max(all_times)
            bins = np.linspace(min_time, max_time, 30)
        else:
            bins = 30
        
        # Cold start (warmup) histogram
        if warmup_response_times:
            ax.hist(
                warmup_response_times,
                bins=bins,
                edgecolor='black',
                alpha=0.6,
                color='orange',
                label=f'Cold Start (Warm-up) ({len(warmup_response_times)} requests)'
            )
        
        # Performance test histogram
        if performance_response_times:
            ax.hist(
                performance_response_times,
                bins=bins,
                edgecolor='black',
                alpha=0.6,
                color='steelblue',
                label=f'Performance Test ({len(performance_response_times)} requests)'
            )
        
        # Calculate and display statistics
        stats_lines = []
        
        if warmup_response_times:
            warmup_avg = statistics.mean(warmup_response_times)
            warmup_median = statistics.median(warmup_response_times)
            ax.axvline(warmup_avg, color='red', linestyle='--', linewidth=1.5, alpha=0.7, 
                     label=f'Cold Start Avg: {warmup_avg:.3f}s')
            stats_lines.append(f'Cold Start: {len(warmup_response_times)} requests')
            stats_lines.append(f'  Avg: {warmup_avg:.3f}s')
            stats_lines.append(f'  Median: {warmup_median:.3f}s')
        
        if performance_response_times:
            perf_avg = statistics.mean(performance_response_times)
            perf_median = statistics.median(performance_response_times)
            ax.axvline(perf_avg, color='blue', linestyle='--', linewidth=1.5, alpha=0.7,
                     label=f'Performance Test Avg: {perf_avg:.3f}s')
            if not stats_lines:
                stats_lines.append('Performance Test:')
            stats_lines.append(f'  {len(performance_response_times)} requests')
            stats_lines.append(f'  Avg: {perf_avg:.3f}s')
            stats_lines.append(f'  Median: {perf_median:.3f}s')
        
        if all_times:
            stats_lines.append(f'\nOverall Min: {min(all_times):.3f}s')
            stats_lines.append(f'Overall Max: {max(all_times):.3f}s')
        
        ax.set_xlabel('Response Time (seconds)', fontsize=12)
        ax.set_ylabel('Frequency', fontsize=12)
        ax.set_title('STT API Response Time Histogram (Cold Start vs Performance Test)', fontsize=14, fontweight='bold')
        ax.legend(fontsize=10, loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # í†µê³„ ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        stats_text = '\n'.join(stats_lines)
        
        ax.text(0.98, 0.98, stats_text,
                transform=ax.transAxes,
                fontsize=9,
                verticalalignment='top',
                horizontalalignment='right',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š íˆìŠ¤í† ê·¸ë¨ì´ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def save_timeline_graph(self, filename: Optional[str] = None):
        """ìš”ì²­ ì¸ë±ìŠ¤ë³„ ì‘ë‹µ ì‹œê°„ ì¶”ì´ ê·¸ë˜í”„ë¥¼ ì €ì¥"""
        # ëª¨ë“  ìš”ì²­ ê²°ê³¼ ìˆ˜ì§‘ (cold start + ì„±ëŠ¥ í…ŒìŠ¤íŠ¸)
        all_results = self.warmup_results + self.results
        successful_results = [r for r in all_results if r.success]
        
        if not successful_results:
            print("âš ï¸ ì„±ê³µí•œ ìš”ì²­ì´ ì—†ì–´ íƒ€ì„ë¼ì¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"response_time_timeline_{timestamp}.png"
        
        # Font settings
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(14, 7))
        
        # ìš”ì²­ ì¸ë±ìŠ¤ì™€ ì‘ë‹µ ì‹œê°„ ë¶„ë¦¬
        request_indices = []
        response_times = []
        is_warmup_list = []
        
        # Warmup ê²°ê³¼ ì¶”ê°€
        for idx, result in enumerate(self.warmup_results):
            if result.success:
                request_indices.append(idx + 1)
                response_times.append(result.response_time)
                is_warmup_list.append(True)
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ê°€
        warmup_count = len([r for r in self.warmup_results if r.success])
        for idx, result in enumerate(self.results):
            if result.success:
                request_indices.append(warmup_count + idx + 1)
                response_times.append(result.response_time)
                is_warmup_list.append(False)
        
        # Cold startì™€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„
        warmup_indices = [idx for idx, is_warmup in zip(request_indices, is_warmup_list) if is_warmup]
        warmup_times = [time for time, is_warmup in zip(response_times, is_warmup_list) if is_warmup]
        perf_indices = [idx for idx, is_warmup in zip(request_indices, is_warmup_list) if not is_warmup]
        perf_times = [time for time, is_warmup in zip(response_times, is_warmup_list) if not is_warmup]
        
        # Cold start í”Œë¡¯
        if warmup_indices:
            ax.scatter(warmup_indices, warmup_times, 
                      color='orange', alpha=0.6, s=30, 
                      label=f'Cold Start (Warm-up) ({len(warmup_indices)} requests)')
            ax.plot(warmup_indices, warmup_times, 
                   color='orange', alpha=0.3, linewidth=1)
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í”Œë¡¯
        if perf_indices:
            ax.scatter(perf_indices, perf_times, 
                      color='steelblue', alpha=0.6, s=30,
                      label=f'Performance Test ({len(perf_indices)} requests)')
            ax.plot(perf_indices, perf_times, 
                   color='steelblue', alpha=0.3, linewidth=1)
        
        # í‰ê· ì„  í‘œì‹œ
        if warmup_times:
            warmup_avg = statistics.mean(warmup_times)
            ax.axhline(warmup_avg, color='red', linestyle='--', linewidth=1.5, alpha=0.7,
                      label=f'Cold Start Avg: {warmup_avg:.3f}s')
        
        if perf_times:
            perf_avg = statistics.mean(perf_times)
            ax.axhline(perf_avg, color='blue', linestyle='--', linewidth=1.5, alpha=0.7,
                      label=f'Performance Test Avg: {perf_avg:.3f}s')
        
        # Cold startì™€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²½ê³„ì„  í‘œì‹œ
        if warmup_indices and perf_indices:
            boundary = max(warmup_indices)
            ax.axvline(boundary, color='gray', linestyle=':', linewidth=1, alpha=0.5,
                      label='Warm-up / Performance Test Boundary')
        
        ax.set_xlabel('Request Index', fontsize=12)
        ax.set_ylabel('Response Time (seconds)', fontsize=12)
        ax.set_title('STT API Response Time Timeline (All Requests)', fontsize=14, fontweight='bold')
        ax.legend(fontsize=9, loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # í†µê³„ ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        stats_lines = []
        if warmup_times:
            stats_lines.append(f'Cold Start: {len(warmup_times)} requests')
            stats_lines.append(f'  Avg: {statistics.mean(warmup_times):.3f}s')
            stats_lines.append(f'  Median: {statistics.median(warmup_times):.3f}s')
        if perf_times:
            if stats_lines:
                stats_lines.append('')
            stats_lines.append(f'Performance Test: {len(perf_times)} requests')
            stats_lines.append(f'  Avg: {statistics.mean(perf_times):.3f}s')
            stats_lines.append(f'  Median: {statistics.median(perf_times):.3f}s')
        
        if response_times:
            stats_lines.append('')
            stats_lines.append(f'Overall Min: {min(response_times):.3f}s')
            stats_lines.append(f'Overall Max: {max(response_times):.3f}s')
        
        stats_text = '\n'.join(stats_lines)
        ax.text(0.02, 0.98, stats_text,
                transform=ax.transAxes,
                fontsize=9,
                verticalalignment='top',
                horizontalalignment='left',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“ˆ íƒ€ì„ë¼ì¸ ê·¸ë˜í”„ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def save_results(self, metrics: PerformanceMetrics, filename: Optional[str] = None):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"stt_load_test_results_{timestamp}.json"
        
        data = {
            "timestamp": datetime.now().isoformat(),
            "test_config": {
                "total_requests": self.total_requests,
                "warmup_requests": self.warmup_requests,
                "concurrent_requests": self.concurrent_requests,
                "request_delay": self.request_delay
            },
            "metrics": {
                "total_requests": metrics.total_requests,
                "successful_requests": metrics.successful_requests,
                "failed_requests": metrics.failed_requests,
                "avg_response_time": metrics.avg_response_time,
                "min_response_time": metrics.min_response_time,
                "max_response_time": metrics.max_response_time,
                "median_response_time": metrics.median_response_time,
                "p95_response_time": metrics.p95_response_time,
                "p99_response_time": metrics.p99_response_time,
                "requests_per_second": metrics.requests_per_second
            },
            "detailed_results": [
                {
                    "response_time": r.response_time,
                    "success": r.success,
                    "error": r.error
                }
                for r in self.results
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # íˆìŠ¤í† ê·¸ë¨ê³¼ íƒ€ì„ë¼ì¸ ê·¸ë˜í”„ ì €ì¥
        self.save_histogram()
        self.save_timeline_graph()


def generate_random_audio(duration_seconds: float = 10.0, sample_rate: int = 16000) -> io.BytesIO:
    """
    ëœë¤ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ WAV íŒŒì¼ í˜•ì‹ì˜ BytesIO ê°ì²´ë¡œ ë°˜í™˜
    
    Args:
        duration_seconds: ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ) - ê¸°ë³¸ê°’: 10.0
        sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz) - ê¸°ë³¸ê°’: 16000
    
    Returns:
        WAV í˜•ì‹ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë‹´ì€ BytesIO ê°ì²´
    """
    # ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    num_samples = int(duration_seconds * sample_rate)
    
    # ëœë¤ ì˜¤ë””ì˜¤ ë°ì´í„° ìƒì„± (í™”ì´íŠ¸ ë…¸ì´ì¦ˆ + ì—¬ëŸ¬ ì£¼íŒŒìˆ˜ ì¡°í•©)
    # ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ ì„±ë¶„ì„ ì¶”ê°€í•˜ì—¬ ë” í˜„ì‹¤ì ì¸ ì˜¤ë””ì˜¤ ìƒì„±
    t = np.linspace(0, duration_seconds, num_samples)
    
    # ëœë¤ ì£¼íŒŒìˆ˜ì™€ ì§„í­ìœ¼ë¡œ ì—¬ëŸ¬ ì‚¬ì¸íŒŒ ìƒì„±
    audio_data = np.zeros(num_samples)
    num_components = random.randint(3, 8)
    
    for _ in range(num_components):
        frequency = random.uniform(100, 2000)  # 100Hz ~ 2000Hz
        amplitude = random.uniform(0.1, 0.5)
        phase = random.uniform(0, 2 * np.pi)
        audio_data += amplitude * np.sin(2 * np.pi * frequency * t + phase)
    
    # í™”ì´íŠ¸ ë…¸ì´ì¦ˆ ì¶”ê°€
    noise = np.random.normal(0, 0.1, num_samples)
    audio_data += noise
    
    # ì •ê·œí™” (-1.0 ~ 1.0 ë²”ìœ„ë¡œ)
    max_val = np.max(np.abs(audio_data))
    if max_val > 0:
        audio_data = audio_data / max_val * 0.8  # í´ë¦¬í•‘ ë°©ì§€ë¥¼ ìœ„í•´ 0.8ë¡œ ì œí•œ
    
    # 16-bit PCMìœ¼ë¡œ ë³€í™˜
    audio_int16 = (audio_data * 32767).astype(np.int16)
    
    # WAV íŒŒì¼ë¡œ ë³€í™˜
    wav_buffer = io.BytesIO()
    try:
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)  # ëª¨ë…¸
            wav_file.setsampwidth(2)  # 16-bit = 2 bytes
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
        
        # wave.openì´ ë‹«íŒ í›„ì— seek
        wav_buffer.seek(0)
        
        # WAV íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if wav_buffer.getvalue() == b'':
            raise ValueError("WAV íŒŒì¼ ìƒì„± ì‹¤íŒ¨: ë¹ˆ íŒŒì¼")
        
        return wav_buffer
    except Exception as e:
        raise ValueError(f"WAV íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

# HTTP STT API í˜¸ì¶œ í•¨ìˆ˜
async def http_stt_call(audio_data: io.BytesIO, base_url: str, endpoint: str):
    """HTTP STT API í˜¸ì¶œ"""
    import aiohttp
    
    url = f"{base_url}{endpoint}"
    
    async with aiohttp.ClientSession() as session:
        # BytesIOë¥¼ ë°”ì´íŠ¸ ë°ì´í„°ë¡œ ì½ê¸°
        audio_data.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ
        audio_bytes = audio_data.read()
        
        data = aiohttp.FormData()
        # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì „ì†¡
        data.add_field('file', audio_bytes, filename='audio.wav', content_type='audio/wav')
        # í•„ìš”ì‹œ ì¶”ê°€ í•„ë“œ (ì˜ˆ: model, language ë“±)
        # data.add_field('model', 'whisper-1')
        
        try:
            async with session.post(url, data=data) as response:
                response_text = await response.text()
                
                if response.status == 200:
                    try:
                        return await response.json()
                    except:
                        # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ ë°˜í™˜
                        return {"text": response_text}
                else:
                    raise Exception(f"API í˜¸ì¶œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status}): {response_text}")
        except aiohttp.ClientError as e:
            raise Exception(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        except Exception as e:
            raise Exception(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")


def load_config(config_path: str = "config.yaml") -> Dict:
    """
    YAML ì„¤ì • íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    
    Args:
        config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.yaml)
    
    Returns:
        ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return config


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¤ì • íŒŒì¼ ì½ê¸°
    config_path = os.getenv("CONFIG_PATH", "config.yaml")
    
    try:
        config = load_config(config_path)
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        print(f"ğŸ’¡ config.yaml íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    except yaml.YAMLError as e:
        print(f"âŒ ì˜¤ë¥˜: YAML íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return
    
    # ì„¤ì • ê°’ ì¶”ì¶œ (ê¸°ë³¸ê°’ í¬í•¨)
    total_requests = config.get("total_requests", 100)
    warmup_requests = config.get("warmup_requests", 10)
    concurrent_requests = config.get("concurrent_requests", 5)
    request_delay = config.get("request_delay", 0.0)
    audio_duration = config.get("audio_duration", 10.0)
    sample_rate = config.get("sample_rate", 16000)
    save_path = config.get("save_path", None)
    base_url = config.get("api", {}).get("base_url", "http://192.168.73.172:8000")
    endpoint = config.get("api", {}).get("endpoint", "/v1/audio/transcriptions")
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if warmup_requests >= total_requests:
        print("âŒ ì˜¤ë¥˜: warmup_requestsëŠ” total_requestsë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ì„¤ì • íŒŒì¼: {config_path}")
    print(f"ğŸµ ì˜¤ë””ì˜¤ ì„¤ì •: ê¸¸ì´ {audio_duration}ì´ˆ, ìƒ˜í”Œë§ ë ˆì´íŠ¸ {sample_rate}Hz")
    print(f"   ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆë¡œìš´ ëœë¤ ì˜¤ë””ì˜¤ ìƒì„± (ìºì‹œ ë°©ì§€)")
    print(f"ğŸŒ API ì„¤ì •: {base_url}{endpoint}")
    print()
    
    # ì˜¤ë””ì˜¤ ìƒì„± í•¨ìˆ˜
    def audio_generator():
        """ëœë¤ ì˜¤ë””ì˜¤ ìƒì„± í•¨ìˆ˜ (ì‹œê°„ ì¸¡ì • ì œì™¸)"""
        return generate_random_audio(
            duration_seconds=audio_duration,
            sample_rate=sample_rate
        )
    
    # API í˜¸ì¶œ í•¨ìˆ˜ (ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì¸ìë¡œ ë°›ìŒ)
    async def api_call_func(audio_data: io.BytesIO):
        """STT API í˜¸ì¶œ í•¨ìˆ˜ (ì‹œê°„ ì¸¡ì •ì— í¬í•¨)"""
        return await http_stt_call(audio_data, base_url, endpoint)
    
    # í…ŒìŠ¤í„° ìƒì„± ë° ì‹¤í–‰
    tester = STTLoadTester(
        api_call_func=api_call_func,
        audio_generator_func=audio_generator,
        total_requests=total_requests,
        warmup_requests=warmup_requests,
        concurrent_requests=concurrent_requests,
        request_delay=request_delay
    )
    
    metrics = await tester.run()
    tester.print_results(metrics)
    
    # ê²°ê³¼ ì €ì¥
    tester.save_results(metrics, save_path)


if __name__ == "__main__":
    asyncio.run(main())